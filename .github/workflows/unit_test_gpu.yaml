name: unit test

on:
  push:
    branches: [ main ]
  pull_request:

jobs:
  unit_tests:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [linux.4xlarge.nvidia.gpu]
        python-version: [3.7]
        cuda-tag: ["cu11"]
    steps:
      - name: Check out repo
        uses: actions/checkout@v2
      - name: Setup conda env
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniconda-version: "latest"
          activate-environment: test
          python-version: ${{ matrix.python-version }}
      - name: Install CUDA 11.3
        shell: sudo bash -l {0}
        run: |
          yum install -y wget curl perl util-linux xz bzip2 git patch which unzip
          yum install -y yum-utils centos-release-scl
          yum-config-manager --enable rhel-server-rhscl-7-rpms
          yum install -y devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-gcc-gfortran devtoolset-9-binutils
          # EPEL for cmake
          wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && \
              rpm -ivh epel-release-latest-7.noarch.rpm && \
              rm -f epel-release-latest-7.noarch.rpm
          # cmake
          yum install -y cmake3 && \
              ln -s /usr/bin/cmake3 /usr/bin/cmake
          ENV PATH=/opt/rh/devtoolset-9/root/usr/bin:$PATH
          ENV LD_LIBRARY_PATH=/opt/rh/devtoolset-9/root/usr/lib64:/opt/rh/devtoolset-9/root/usr/lib:$LD_LIBRARY_PATH

          yum install -y autoconf aclocal automake make sudo
          rm -rf /usr/local/cuda-*

          echo "Installing CUDA 11.3 and CuDNN 8.3"
          rm -rf /usr/local/cuda-11.3 /usr/local/cuda
          # install CUDA 11.3.1 in the same container
          wget -q https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda_11.3.1_465.19.01_linux.run
          chmod +x cuda_11.3.1_465.19.01_linux.run
          ./cuda_11.3.1_465.19.01_linux.run --toolkit --silent
          rm -f cuda_11.3.1_465.19.01_linux.run
          rm -f /usr/local/cuda && ln -s /usr/local/cuda-11.3 /usr/local/cuda

          # cuDNN license: https://developer.nvidia.com/cudnn/license_agreement
          mkdir tmp_cudnn && cd tmp_cudnn
          wget -q https://developer.download.nvidia.com/compute/redist/cudnn/v8.3.2/local_installers/11.5/cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive.tar.xz -O cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive.tar.xz
          tar xf cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive.tar.xz
          cp -a cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive/include/* /usr/local/cuda/include/
          cp -a cudnn-linux-x86_64-8.3.2.44_cuda11.5-archive/lib/* /usr/local/cuda/lib64/
          cd ..
          rm -rf tmp_cudnn
          ldconfig
      - name: Check ldd --version
        run: ldd --version
      - name: check cpu info
        shell: bash
        run: |
          cat /proc/cpuinfo
      - name: check distribution info
        shell: bash
        run: |
          cat /proc/version
      - name: Display EC2 information
        shell: bash
        run: |
          set -euo pipefail
          function get_ec2_metadata() {
            # Pulled from instance metadata endpoint for EC2
            # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html
            category=$1
            curl -fsSL "http://169.254.169.254/latest/meta-data/${category}"
          }
          echo "ami-id: $(get_ec2_metadata ami-id)"
          echo "instance-id: $(get_ec2_metadata instance-id)"
          echo "instance-type: $(get_ec2_metadata instance-type)"
      - name: check gpu info
        shell: bash
        run: |
          sudo yum install lshw -y
          sudo lshw -C display
          # sudo yum update -y
      - name: Install dependencies
        shell: bash -l {0}
        run: |
          set -eux
          conda activate test
          pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html
          python -c "import torch; print(torch.cuda.is_available())"
      - name: nvcc check
        run: |
          nvcc --version
          nvidia-smi
      #     pip install -r requirements.txt
      #     pip install -r dev-requirements.txt
      #     pip install -e ".[dev]"
      # - name: Run unit tests with coverage
      #   shell: bash -l {0}
      #   run: |
      #     set -eux
      #     conda activate test
      #     pytest --cov=. --cov-report xml tests -vv
      # - name: Upload Coverage to Codecov
      #   uses: codecov/codecov-action@v2
